---
date: 2024-04-02
authors:
  - robin-l
categories:
  - Feature Updates
---

# Splink 3 updates, and Splink 4 development announcement - April 2024

This post describes significant updates to Splink since our previous [post](https://moj-analytical-services.github.io/splink/blog/2023/12/06/splink-updates---december-2023.html) and details of development work taking place on the forthcoming release of Splink 4.

<!-- more -->

Latest Splink version: [v3.9.14](https://github.com/moj-analytical-services/splink/releases/tag/v3.9.14)



## Splink 3 Updates

Here are some highlights of Splink development since our [last update](https://moj-analytical-services.github.io/splink/blog/2023/12/06/splink-updates---december-2023.html) in December 2023. As always, keep an eye on the [changelog](https://github.com/moj-analytical-services/splink/blob/master/CHANGELOG.md) for more regular updates.

### :simple-graphql: Graph metrics

Linked data can be interpreted as graphs, as described in our [graph definitions guide](../../topic_guides/theory/linked_data_as_graphs.md). Given this, graph metrics are useful in record linkage because they give insights into the quality of your final output (linked data) and, by extension, the linkage pipeline. They are particularly relevant for the analysis of [clusters](https://moj-analytical-services.github.io/splink/linker.html?h=graph#splink.linker.Linker.cluster_pairwise_predictions_at_threshold).

For example, a cluster where all entities are connected to all others with high match weights is likely to be more reliable than a cluster where many of the entities connect to only a small proportion of the other entities in the cluster. This can be measured by a graph metric called density.

Several graph metrics can now be computed using [`linker.compute_graph_metrics`](https://moj-analytical-services.github.io/splink/linker.html?h=graph#splink.linker.Linker.compute_graph_metrics).

### :rocket: DuckDB Performance Improvements and Benchmarking

The DuckDB backend is [now fully parallelised,](https://github.com/moj-analytical-services/splink/pull/1796) resulting in large performance increases especially on high core count machines.

We [now](https://github.com/moj-analytical-services/splink/commit/0f1a87a7917051e55af3d7d11379736abe94787a) recommend the DuckDB backend for most users. It is the fastest backend, and is capable of linking large datasets, especially if you have access to high-spec machines.

For the first time, we have also conducted formal benchmarking of DuckDB on machines of different sizes. Check out our [blog post](https://www.robinlinacre.com/fast_deduplication/) outlining the results of this investigation.

### :simple-adblock: Blocking on an array column

In some circumstances, it is useful to block on an array column. For example, if a persons have an array (list) of postcodes associated with each record, then we may wish to generate all record comparisons where there is a match of at least one postcode (the union of the arrays is of length 1 or more). This feature was added in [PR 1692](https://github.com/moj-analytical-services/splink/pull/1692), with thanks to Github user [`nerskin`](https://github.com/nerskin) for this external contribution!

### :books: More Documentation

We have been building more guidance and documentation to make life as easy as possible for users, including:

* Topic Guides exploring [Evaluation](../../topic_guides/evaluation/overview.md) for different outputs of the linkage process, including the [Linkage Model](../../topic_guides/evaluation/model.md), the [Edges (Links)](../../topic_guides/evaluation/edge_overview.md) and [Clusters](../../topic_guides/evaluation/clusters/overview.md).
* Guidance on our strategy for [Managing Dependencies](../../dev_guides/dependency_compatibility_policy.md) within Splink.
* A [Developer Quickstart](../../dev_guides/changing_splink/development_quickstart.md) guide to help contributors get up and running smoothly (with thanks to external contributor [`zmbc`](https://github.com/zmbc) for putting this together).


!!! warning

    Splink 3 has entered maintenance mode.  We will continue to apply bugfixes, but new features should be built on the [splink4_dev](https://github.com/moj-analytical-services/splink/tree/splink4_dev) branch.  We are no longer accepting new features on the master (Splink 3) branch.

## Splink 4

The team has been focussing development efforts on [Splink 4](https://github.com/moj-analytical-services/splink/tree/splink4_dev), due to be released later this year.

We’re pleased to announce we’ve recently reached an important milestone: all tests are passing, and all of the tutorial and examples notebooks have been updated and work successfully in the new version

Development releases of Splink 4 have commenced, and you can try it out using `pip install --pre splink`, or try it out in your web browser using the Colab links at the top the [tutorial](https://github.com/moj-analytical-services/splink/tree/splink4_dev/docs/demos/tutorials) and [example](https://github.com/moj-analytical-services/splink/tree/splink4_dev/docs/demos/examples/duckdb) notebooks.

As a result, Splink 3 has entered maintenance mode. We will continue to apply bugfixes, but new features should be built on the [splink4_dev](https://github.com/moj-analytical-services/splink/tree/splink4_dev) branch. We are no longer accepting new features on the master (Splink 3) branch.

### :material-target: Aims of Splink 4

Splink 4 represents an incremental improvement to version 3 that makes Splink easier to use without making any major changes to workflows. The core functionality has not changed - the steps to train a model and predict results are the same, and models trained in Splink 3 will still work in Splink 4.

#### Improve ease of use

The primary aim is to improve the user-facing API so that:

- The user has to write less code to achieve the same result
- Function imports are simpler and grouped more intuitively
- Settings and configuration can now be constructed entirely using Python objects, meaning that the user can rely heavily on autocomplete, rather than needing to remember the names of settings.
- Less dialect-specific code

You can see an example of how the code changes between version 3 and 4 in the screenshot below:

[![image](https://gist.github.com/assets/2608005/239eb264-5f79-4db0-a958-d10fdc35d689)](https://gist.github.com/assets/2608005/239eb264-5f79-4db0-a958-d10fdc35d689)

The corresponding code is [here](https://gist.github.com/RobinL/c99712c1fb0b6c80593b5028c0be553a).

#### Improve ease of development

A second important aim of Splink 4 is to improve the internal codebase to make Splink easier to develop for the core team and external contributors. These changes don’t affect the end user, but should enable a faster pace of development.

A wide range of improvements have been made such as:

- Code quality: type hinting, mypy conformance etc.
- Making CI run much faster
- Reducing rigidities in dependencies
- Decoupling parts of the codebase and less [mutable state](https://softwareengineering.stackexchange.com/questions/235558/what-is-state-mutable-state-and-immutable-state)

### :calendar_spiral: Timelines

We expect to do regular beta releases to PyPI in the coming months. They can be found [here](https://pypi.org/project/splink/#history), and you can install the latest version of Splink 4 using `pip install --pre splink`

!!! warning

    During this time, there may be further breaking changes to the public API so please use Splink 4 with caution. However, we think the new API is now relatively stable, and big changes are unlikely.

We expect to bring Splink 4 out of beta, and do a first full release sometime in the autumn.

### :speaking_head: Feedback

We would love feedback on Splink 4, so please check it out and let us know what you think! The best way to get in contact is via our [discussion forum](https://github.com/moj-analytical-services/splink/discussions).
